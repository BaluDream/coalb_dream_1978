{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "a9d79da1-6001-4f97-8381-b11b5516e640",
      "metadata": {
        "id": "a9d79da1-6001-4f97-8381-b11b5516e640",
        "tags": []
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/open-mmlab/mmtracking/blob/master/demo/MMTracking_Tutorial.ipynb)\n",
        "\n",
        "# **Welcome to MMTracking**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "527a563a-c8b2-44f0-ae20-0d226ab1e547",
      "metadata": {
        "id": "527a563a-c8b2-44f0-ae20-0d226ab1e547"
      },
      "source": [
        "In this tutorial, you will learn to:\n",
        "+ Install MMTracking.\n",
        "+ Perform inference with pretrained weights in MMTracking.\n",
        "+ Train a new MOT model with a toy dataset.\n",
        "Let's start!"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ab2c382c-a169-46fe-938f-c6687d763e8e",
      "metadata": {
        "id": "ab2c382c-a169-46fe-938f-c6687d763e8e"
      },
      "source": [
        "## **Install MMTracking**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f8ced8f4-b07b-4216-8953-f7af6928b77c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f8ced8f4-b07b-4216-8953-f7af6928b77c",
        "outputId": "1a1e1463-e8a6-4234-fa5a-fc9602b60623"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2022 NVIDIA Corporation\n",
            "Built on Wed_Sep_21_10:33:58_PDT_2022\n",
            "Cuda compilation tools, release 11.8, V11.8.89\n",
            "Build cuda_11.8.r11.8/compiler.31833905_0\n",
            "gcc (Ubuntu 9.4.0-1ubuntu1~20.04.1) 9.4.0\n",
            "Copyright (C) 2019 Free Software Foundation, Inc.\n",
            "This is free software; see the source for copying conditions.  There is NO\n",
            "warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Check nvcc version\n",
        "!nvcc -V\n",
        "# Check GCC version\n",
        "!gcc --version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6b4f093f-e197-42bd-ba64-dc905e379382",
      "metadata": {
        "id": "6b4f093f-e197-42bd-ba64-dc905e379382",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce8a0b4a-a89d-4890-863e-86dca8513422"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Looking in links: https://download.openmmlab.com/mmcv/dist/cu111/torch1.10.0/index.html\n",
            "Collecting mmcv-full\n",
            "  Downloading mmcv-full-1.7.1.tar.gz (605 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m605.4/605.4 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting addict (from mmcv-full)\n",
            "  Downloading addict-2.4.0-py3-none-any.whl (3.8 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from mmcv-full) (1.22.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from mmcv-full) (23.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from mmcv-full) (8.4.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from mmcv-full) (6.0)\n",
            "Collecting yapf (from mmcv-full)\n",
            "  Downloading yapf-0.33.0-py2.py3-none-any.whl (200 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m200.9/200.9 kB\u001b[0m \u001b[31m23.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tomli>=2.0.1 in /usr/local/lib/python3.10/dist-packages (from yapf->mmcv-full) (2.0.1)\n",
            "Building wheels for collected packages: mmcv-full\n"
          ]
        }
      ],
      "source": [
        "# install MMCV\n",
        "!pip install mmcv-full -f https://download.openmmlab.com/mmcv/dist/cu111/torch1.10.0/index.html\n",
        "\n",
        "# install MMDetection\n",
        "!pip install mmdet\n",
        "\n",
        "# clone the MMTracking repository\n",
        "!git clone https://github.com/open-mmlab/mmtracking.git\n",
        "%cd mmtracking\n",
        "\n",
        "# install MMTracking and its dependencies\n",
        "!pip install -r requirements/build.txt\n",
        "!pip install -e .\n",
        "# used to MOT evaluation\n",
        "!pip install git+https://github.com/JonathonLuiten/TrackEval.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "03a4a583-78e7-40a1-a6ef-d80056989546",
      "metadata": {
        "id": "03a4a583-78e7-40a1-a6ef-d80056989546"
      },
      "outputs": [],
      "source": [
        "from mmcv import collect_env\n",
        "collect_env()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ff6aea79-2ce9-4b1c-b3c4-3f92d1a4e34c",
      "metadata": {
        "id": "ff6aea79-2ce9-4b1c-b3c4-3f92d1a4e34c"
      },
      "outputs": [],
      "source": [
        "# Check Pytorch installation\n",
        "import torch, torchvision\n",
        "print(torch.__version__, torch.cuda.is_available())\n",
        "\n",
        "# Check mmcv installation\n",
        "from mmcv.ops import get_compiling_cuda_version, get_compiler_version\n",
        "print(get_compiling_cuda_version())\n",
        "print(get_compiler_version())\n",
        "\n",
        "# Check MMDetection installation\n",
        "import mmdet\n",
        "print(mmdet.__version__)\n",
        "\n",
        "# Check MMTracking installation\n",
        "import mmtrack\n",
        "print(mmtrack.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4d43b49c-320a-4b0f-baca-fb4bde0630ff",
      "metadata": {
        "id": "4d43b49c-320a-4b0f-baca-fb4bde0630ff",
        "tags": []
      },
      "source": [
        "## **Perform inference**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dd7c8466-f057-455f-985a-71e5f22c36e4",
      "metadata": {
        "id": "dd7c8466-f057-455f-985a-71e5f22c36e4"
      },
      "outputs": [],
      "source": [
        "# unset the proxy for downloading the pretrained models (optional)\n",
        "!unset https_proxy\n",
        "!unset http_proxy\n",
        "\n",
        "# download checkpoints\n",
        "!mkdir checkpoints\n",
        "!wget -c https://download.openmmlab.com/mmtracking/vid/selsa/selsa_faster_rcnn_r50_dc5_1x_imagenetvid/selsa_faster_rcnn_r50_dc5_1x_imagenetvid_20201227_204835-2f5a4952.pth -P ./checkpoints\n",
        "!wget -c https://download.openmmlab.com/mmtracking/sot/siamese_rpn/siamese_rpn_r50_1x_lasot/siamese_rpn_r50_1x_lasot_20211203_151612-da4b3c66.pth -P ./checkpoints\n",
        "!wget -c https://download.openmmlab.com/mmtracking/vis/masktrack_rcnn/masktrack_rcnn_r50_fpn_12e_youtubevis2019/masktrack_rcnn_r50_fpn_12e_youtubevis2019_20211022_194830-6ca6b91e.pth -P ./checkpoints"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "420dae4b-4426-405e-97fb-7823943b8ee8",
      "metadata": {
        "id": "420dae4b-4426-405e-97fb-7823943b8ee8"
      },
      "outputs": [],
      "source": [
        "# run mot demo\n",
        "import mmcv\n",
        "import tempfile\n",
        "from mmtrack.apis import inference_mot, init_model\n",
        "mot_config = './configs/mot/deepsort/deepsort_faster-rcnn_fpn_4e_mot17-private-half.py'\n",
        "input_video = './demo/demo.mp4'\n",
        "imgs = mmcv.VideoReader(input_video)\n",
        "# build the model from a config file\n",
        "mot_model = init_model(mot_config, device='cuda:0')\n",
        "prog_bar = mmcv.ProgressBar(len(imgs))\n",
        "out_dir = tempfile.TemporaryDirectory()\n",
        "out_path = out_dir.name\n",
        "# test and show/save the images\n",
        "for i, img in enumerate(imgs):\n",
        "    result = inference_mot(mot_model, img, frame_id=i)\n",
        "    mot_model.show_result(\n",
        "            img,\n",
        "            result,\n",
        "            show=False,\n",
        "            wait_time=int(1000. / imgs.fps),\n",
        "            out_file=f'{out_path}/{i:06d}.jpg')\n",
        "    prog_bar.update()\n",
        "\n",
        "output = './demo/mot.mp4'\n",
        "print(f'\\n making the output video at {output} with a FPS of {imgs.fps}')\n",
        "mmcv.frames2video(out_path, output, fps=imgs.fps, fourcc='mp4v')\n",
        "out_dir.cleanup()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d4a97033-b779-4169-84c9-781c58840ae5",
      "metadata": {
        "id": "d4a97033-b779-4169-84c9-781c58840ae5"
      },
      "outputs": [],
      "source": [
        "# run vis demo\n",
        "from mmtrack.apis import inference_mot\n",
        "vis_config = './configs/vis/masktrack_rcnn/masktrack_rcnn_r50_fpn_12e_youtubevis2019.py'\n",
        "vis_checkpoint = './checkpoints/masktrack_rcnn_r50_fpn_12e_youtubevis2019_20211022_194830-6ca6b91e.pth'\n",
        "# build the model from a config file and a checkpoint file\n",
        "vis_model = init_model(vis_config, vis_checkpoint, device='cuda:0')\n",
        "imgs = mmcv.VideoReader(input_video)\n",
        "prog_bar = mmcv.ProgressBar(len(imgs))\n",
        "out_dir = tempfile.TemporaryDirectory()\n",
        "out_path = out_dir.name\n",
        "for i, img in enumerate(imgs):\n",
        "    result = inference_mot(vis_model, img, frame_id=i)\n",
        "    vis_model.show_result(\n",
        "            img,\n",
        "            result,\n",
        "            wait_time=int(1000. / imgs.fps),\n",
        "            out_file=f'{out_path}/{i:06d}.jpg')\n",
        "    prog_bar.update()\n",
        "output = './demo/vis.mp4'\n",
        "print(f'\\n making the output video at {output} with a FPS of {imgs.fps}')\n",
        "mmcv.frames2video(out_path, output, fps=imgs.fps, fourcc='mp4v')\n",
        "out_dir.cleanup()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "abd0863b-933c-42d1-8442-70565d1b4b55",
      "metadata": {
        "id": "abd0863b-933c-42d1-8442-70565d1b4b55"
      },
      "outputs": [],
      "source": [
        "# run vid demo\n",
        "from mmtrack.apis import inference_vid\n",
        "vid_config = './configs/vid/selsa/selsa_faster_rcnn_r50_dc5_1x_imagenetvid.py'\n",
        "vid_checkpoint = './checkpoints/selsa_faster_rcnn_r50_dc5_1x_imagenetvid_20201227_204835-2f5a4952.pth'\n",
        "# build the model from a config file and a checkpoint file\n",
        "vid_model = init_model(vid_config, vid_checkpoint, device='cuda:0')\n",
        "imgs = mmcv.VideoReader(input_video)\n",
        "prog_bar = mmcv.ProgressBar(len(imgs))\n",
        "out_dir = tempfile.TemporaryDirectory()\n",
        "out_path = out_dir.name\n",
        "for i, img in enumerate(imgs):\n",
        "    result = inference_vid(vid_model, img, frame_id=i)\n",
        "    vid_model.show_result(\n",
        "            img,\n",
        "            result,\n",
        "            wait_time=int(1000. / imgs.fps),\n",
        "            out_file=f'{out_path}/{i:06d}.jpg')\n",
        "    prog_bar.update()\n",
        "output = './demo/vid.mp4'\n",
        "print(f'\\n making the output video at {output} with a FPS of {imgs.fps}')\n",
        "mmcv.frames2video(out_path, output, fps=imgs.fps, fourcc='mp4v')\n",
        "out_dir.cleanup()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0189f86a-b216-4f63-a58a-97e40e326869",
      "metadata": {
        "id": "0189f86a-b216-4f63-a58a-97e40e326869"
      },
      "outputs": [],
      "source": [
        "# run sot demo\n",
        "from mmtrack.apis import inference_sot\n",
        "sot_config = './configs/sot/siamese_rpn/siamese_rpn_r50_20e_lasot.py'\n",
        "sot_checkpoint = './checkpoints/siamese_rpn_r50_1x_lasot_20211203_151612-da4b3c66.pth'\n",
        "# build the model from a config file and a checkpoint file\n",
        "sot_model = init_model(sot_config, sot_checkpoint, device='cuda:0')\n",
        "init_bbox = [371, 411, 450, 646]\n",
        "imgs = mmcv.VideoReader(input_video)\n",
        "prog_bar = mmcv.ProgressBar(len(imgs))\n",
        "out_dir = tempfile.TemporaryDirectory()\n",
        "out_path = out_dir.name\n",
        "for i, img in enumerate(imgs):\n",
        "    result = inference_sot(sot_model, img, init_bbox, frame_id=i)\n",
        "    sot_model.show_result(\n",
        "            img,\n",
        "            result,\n",
        "            wait_time=int(1000. / imgs.fps),\n",
        "            out_file=f'{out_path}/{i:06d}.jpg')\n",
        "    prog_bar.update()\n",
        "output = './demo/sot.mp4'\n",
        "print(f'\\n making the output video at {output} with a FPS of {imgs.fps}')\n",
        "mmcv.frames2video(out_path, output, fps=imgs.fps, fourcc='mp4v')\n",
        "out_dir.cleanup()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "500ff07b-9664-4429-9e3f-e97dd4fa1c29",
      "metadata": {
        "id": "500ff07b-9664-4429-9e3f-e97dd4fa1c29",
        "tags": []
      },
      "source": [
        "## **Train a MOT model with a toy dataset**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e7bd4f44-447a-49a5-8c9c-cf160691bda5",
      "metadata": {
        "id": "e7bd4f44-447a-49a5-8c9c-cf160691bda5",
        "tags": []
      },
      "source": [
        "### **Prepare dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a91a55bd-14be-46bf-aa18-5e30d9abe5b7",
      "metadata": {
        "id": "a91a55bd-14be-46bf-aa18-5e30d9abe5b7"
      },
      "outputs": [],
      "source": [
        "!mkdir data\n",
        "!wget https://download.openmmlab.com/mmtracking/data/MOT17_tiny.zip -P ./data\n",
        "!unzip -q ./data/MOT17_tiny.zip -d ./data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d0db0d5f-b192-48ee-b145-149f33ad3685",
      "metadata": {
        "id": "d0db0d5f-b192-48ee-b145-149f33ad3685"
      },
      "outputs": [],
      "source": [
        "# convert the dataset to coco format\n",
        "!python ./tools/convert_datasets/mot/mot2coco.py -i ./data/MOT17_tiny/ -o ./data/MOT17_tiny/annotations --split-train --convert-det\n",
        "# crop pedestrian patches from the original dataset for training reid model. It may take a few minutes.\n",
        "!rm -rf ./data/MOT17_tiny/reid\n",
        "!python ./tools/convert_datasets/mot/mot2reid.py -i ./data/MOT17_tiny/ -o ./data/MOT17_tiny/reid --val-split 0.9 --vis-threshold 0.8"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ae887970-7382-4bd0-a739-6b07e6dded6f",
      "metadata": {
        "id": "ae887970-7382-4bd0-a739-6b07e6dded6f",
        "tags": []
      },
      "source": [
        "### **Train a detector for MOT**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bce04095-8586-45c5-a556-40c51d08b2cb",
      "metadata": {
        "id": "bce04095-8586-45c5-a556-40c51d08b2cb"
      },
      "outputs": [],
      "source": [
        "import mmcv\n",
        "from mmdet.apis import set_random_seed\n",
        "cfg = mmcv.Config.fromfile('./configs/det/faster-rcnn_r50_fpn_4e_mot17-half.py')\n",
        "cfg.data_root = 'data/MOT17_tiny/'\n",
        "cfg.data.test.ann_file = cfg.data.test.ann_file.replace('data/MOT17/','data/MOT17_tiny/')\n",
        "cfg.data.train.ann_file = cfg.data.train.ann_file.replace('data/MOT17/','data/MOT17_tiny/')\n",
        "cfg.data.val.ann_file = cfg.data.val.ann_file.replace('data/MOT17/','data/MOT17_tiny/')\n",
        "\n",
        "cfg.data.test.img_prefix = cfg.data.test.img_prefix.replace('data/MOT17/','data/MOT17_tiny/')\n",
        "cfg.data.train.img_prefix = cfg.data.train.img_prefix.replace('data/MOT17/','data/MOT17_tiny/')\n",
        "cfg.data.val.img_prefix = cfg.data.val.img_prefix.replace('data/MOT17/','data/MOT17_tiny/')\n",
        "\n",
        "cfg.work_dir = './tutorial_exps/detector'\n",
        "cfg.seed = 0\n",
        "set_random_seed(0, deterministic=False)\n",
        "cfg.gpu_ids = range(1)\n",
        "print(f'Config:\\n{cfg.pretty_text}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "889b4255-50be-4da3-85c4-dcd19c8111ac",
      "metadata": {
        "id": "889b4255-50be-4da3-85c4-dcd19c8111ac"
      },
      "outputs": [],
      "source": [
        "import os.path as osp\n",
        "\n",
        "from mmtrack.datasets import build_dataset\n",
        "from mmdet.apis import train_detector as train_model\n",
        "from mmdet.models import build_detector as build_model\n",
        "\n",
        "mmcv.mkdir_or_exist(osp.abspath(cfg.work_dir))\n",
        "model = build_model(cfg.model.detector)\n",
        "model.init_weights()\n",
        "datasets = [build_dataset(cfg.data.train)]\n",
        "model.CLASSES = datasets[0].CLASSES\n",
        "train_model(model, datasets, cfg)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7f747c1f-7944-49f2-b9fc-a51dc3f85857",
      "metadata": {
        "id": "7f747c1f-7944-49f2-b9fc-a51dc3f85857",
        "tags": []
      },
      "source": [
        "### **Train a ReID model for MOT**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6705deeb-a9d7-42e2-9d52-b51b7b588d1f",
      "metadata": {
        "id": "6705deeb-a9d7-42e2-9d52-b51b7b588d1f"
      },
      "outputs": [],
      "source": [
        "import mmcv\n",
        "from mmdet.apis import set_random_seed\n",
        "cfg = mmcv.Config.fromfile('./configs/reid/resnet50_b32x8_MOT17.py')\n",
        "cfg.data_root = 'data/MOT17_tiny/'\n",
        "cfg.data.test.ann_file = cfg.data.test.ann_file.replace('data/MOT17/','data/MOT17_tiny/')\n",
        "cfg.data.train.ann_file = 'data/MOT17_tiny/reid/meta/train_9.txt'\n",
        "cfg.data.val.ann_file = cfg.data.val.ann_file.replace('data/MOT17/','data/MOT17_tiny/')\n",
        "\n",
        "cfg.data.test.data_prefix = cfg.data.test.data_prefix.replace('data/MOT17/','data/MOT17_tiny/')\n",
        "cfg.data.train.data_prefix = cfg.data.train.data_prefix.replace('data/MOT17/','data/MOT17_tiny/')\n",
        "cfg.data.val.data_prefix = cfg.data.val.data_prefix.replace('data/MOT17/','data/MOT17_tiny/')\n",
        "\n",
        "# learning policy\n",
        "cfg.lr_config = dict(\n",
        "    policy='step',\n",
        "    warmup='linear',\n",
        "    warmup_iters=200,\n",
        "    warmup_ratio=1.0 / 200,\n",
        "    step=[1])\n",
        "cfg.total_epochs = 2\n",
        "\n",
        "cfg.work_dir = './tutorial_exps/reid'\n",
        "cfg.seed = 0\n",
        "set_random_seed(0, deterministic=False)\n",
        "cfg.gpu_ids = range(1)\n",
        "print(f'Config:\\n{cfg.pretty_text}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "12f2b54e-7e5f-4d95-9e27-528115717e03",
      "metadata": {
        "id": "12f2b54e-7e5f-4d95-9e27-528115717e03"
      },
      "outputs": [],
      "source": [
        "from mmtrack.datasets import build_dataset\n",
        "from mmdet.apis import train_detector as train_model\n",
        "from mmtrack.models import build_reid as build_model\n",
        "\n",
        "\n",
        "model = build_model(cfg.model.reid)\n",
        "model.init_weights()\n",
        "datasets = [build_dataset(cfg.data.train)]\n",
        "model.CLASSES = datasets[0].CLASSES\n",
        "\n",
        "train_model(model, datasets, cfg)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e5ac4b40-7023-498a-9ddf-bc06ff2100af",
      "metadata": {
        "id": "e5ac4b40-7023-498a-9ddf-bc06ff2100af",
        "tags": []
      },
      "source": [
        "### **Test the DeepSORT model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c837c657-cc81-426d-8060-ad19f5494461",
      "metadata": {
        "id": "c837c657-cc81-426d-8060-ad19f5494461"
      },
      "outputs": [],
      "source": [
        "import mmcv\n",
        "from mmdet.apis import set_random_seed\n",
        "cfg = mmcv.Config.fromfile('./configs/mot/deepsort/deepsort_faster-rcnn_fpn_4e_mot17-private-half.py')\n",
        "cfg.data_root = 'data/MOT17_tiny/'\n",
        "cfg.data.test.ann_file = cfg.data.test.ann_file.replace('data/MOT17/','data/MOT17_tiny/')\n",
        "cfg.data.train.ann_file = cfg.data.test.ann_file.replace('data/MOT17/','data/MOT17_tiny/')\n",
        "cfg.data.val.ann_file = cfg.data.val.ann_file.replace('data/MOT17/','data/MOT17_tiny/')\n",
        "\n",
        "cfg.data.test.img_prefix = cfg.data.test.img_prefix.replace('data/MOT17/','data/MOT17_tiny/')\n",
        "cfg.data.train.img_prefix = cfg.data.train.img_prefix.replace('data/MOT17/','data/MOT17_tiny/')\n",
        "cfg.data.val.img_prefix = cfg.data.val.img_prefix.replace('data/MOT17/','data/MOT17_tiny/')\n",
        "\n",
        "cfg.model.detector.init_cfg.checkpoint = './tutorial_exps/detector/epoch_4.pth'\n",
        "cfg.model.reid.init_cfg.checkpoint = './tutorial_exps/reid/epoch_2.pth'\n",
        "\n",
        "cfg.work_dir = './tutorial_exps'\n",
        "cfg.seed = 0\n",
        "set_random_seed(0, deterministic=False)\n",
        "cfg.gpu_ids = range(1)\n",
        "cfg.data.test.test_mode = True\n",
        "print(f'Config:\\n{cfg.pretty_text}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "29c9f531-3ea9-42d3-9fb3-bcdd13594406",
      "metadata": {
        "id": "29c9f531-3ea9-42d3-9fb3-bcdd13594406"
      },
      "outputs": [],
      "source": [
        "from mmtrack.datasets import build_dataloader\n",
        "from mmtrack.apis import init_model\n",
        "from mmcv.parallel import MMDataParallel\n",
        "from mmtrack.apis import single_gpu_test\n",
        "from mmtrack.datasets import build_dataset\n",
        "\n",
        "dataset = build_dataset(cfg.data.test)\n",
        "data_loader = build_dataloader(\n",
        "    dataset,\n",
        "    samples_per_gpu=1,\n",
        "    workers_per_gpu=cfg.data.workers_per_gpu,\n",
        "    dist=False,\n",
        "    shuffle=False)\n",
        "\n",
        "# build the model and load checkpoint\n",
        "model = init_model(cfg)\n",
        "\n",
        "model = MMDataParallel(model, device_ids=cfg.gpu_ids)\n",
        "outputs = single_gpu_test(model, data_loader)\n",
        "\n",
        "eval_kwargs = cfg.get('evaluation', {}).copy()\n",
        "# hard-code way to remove EvalHook args\n",
        "eval_hook_args = [\n",
        "    'interval', 'tmpdir', 'start', 'gpu_collect', 'save_best',\n",
        "    'rule', 'by_epoch'\n",
        "]\n",
        "for key in eval_hook_args:\n",
        "    eval_kwargs.pop(key, None)\n",
        "eval_kwargs.update(dict(metric=['track']))\n",
        "metric = dataset.evaluate(outputs, **eval_kwargs)\n",
        "print(metric)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}